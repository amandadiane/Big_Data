{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras import regularizers\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "import pandas as pd\n",
    "data = pd.read_csv('data/SpeedDatingData.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove features that will not impact the match\n",
    "data = data.drop(columns=['iid', 'id', 'gender', 'idg', 'condtn', 'wave', 'round', 'position', 'positin1'])\n",
    "# remove features with not enough data\n",
    "data = data.drop(columns=[i for i in data.columns if (data[i].count() < 6000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-8eab2b96dbff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# oversampling data to improve class balance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mdata_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# drop rows with no data in 'match' column\n",
    "data['match'] = pd.to_numeric(data['match'], errors='coerce')\n",
    "data = data.dropna(subset=['match'])\n",
    "\n",
    "# set aside labels as target vector\n",
    "labels = pd.DataFrame([data['match']])\n",
    "data = data.drop(columns=['match'])\n",
    "\n",
    "# remove categorical features\n",
    "cat_cols = [i for i in data.columns if data[i].dtype != 'float']\n",
    "data = data.drop(columns=[i for i in cat_cols])\n",
    "\n",
    "labels[0].apply(lambda x: int(x))\n",
    "labels = labels.T\n",
    "\n",
    "# oversampling data to improve class balance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "data_resampled, labels_resampled = SMOTE().fit_resample(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "match    1380\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5864, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(np.round(len(x_train)*.1))\n",
    "x_val = x_train[:val_size]\n",
    "x_train_minus_val = x_train[val_size:]\n",
    "\n",
    "y_val = y_train[:val_size]\n",
    "y_train_minus_val = y_train[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5278, 93)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_minus_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5278 samples, validate on 586 samples\n",
      "Epoch 1/10\n",
      "5278/5278 [==============================] - 0s 88us/step - loss: 0.7040 - acc: 0.8350 - val_loss: 0.6472 - val_acc: 0.8549\n",
      "Epoch 2/10\n",
      "5278/5278 [==============================] - 0s 25us/step - loss: 0.6345 - acc: 0.8350 - val_loss: 0.6123 - val_acc: 0.8549\n",
      "Epoch 3/10\n",
      "5278/5278 [==============================] - 0s 26us/step - loss: 0.6027 - acc: 0.8350 - val_loss: 0.5791 - val_acc: 0.8549\n",
      "Epoch 4/10\n",
      "5278/5278 [==============================] - 0s 26us/step - loss: 0.5728 - acc: 0.8350 - val_loss: 0.5474 - val_acc: 0.8549\n",
      "Epoch 5/10\n",
      "5278/5278 [==============================] - 0s 25us/step - loss: 0.5444 - acc: 0.8350 - val_loss: 0.5176 - val_acc: 0.8549\n",
      "Epoch 6/10\n",
      "5278/5278 [==============================] - 0s 27us/step - loss: 0.5184 - acc: 0.8350 - val_loss: 0.4905 - val_acc: 0.8549\n",
      "Epoch 7/10\n",
      "5278/5278 [==============================] - 0s 25us/step - loss: 0.4963 - acc: 0.8350 - val_loss: 0.4679 - val_acc: 0.8549\n",
      "Epoch 8/10\n",
      "5278/5278 [==============================] - 0s 28us/step - loss: 0.4790 - acc: 0.8350 - val_loss: 0.4497 - val_acc: 0.8549\n",
      "Epoch 9/10\n",
      "5278/5278 [==============================] - 0s 31us/step - loss: 0.4648 - acc: 0.8350 - val_loss: 0.4344 - val_acc: 0.8549\n",
      "Epoch 10/10\n",
      "5278/5278 [==============================] - 0s 29us/step - loss: 0.4557 - acc: 0.8350 - val_loss: 0.4253 - val_acc: 0.8549\n"
     ]
    }
   ],
   "source": [
    "# train basic RNN\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(93,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax')) \n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_minus_val,\n",
    "                    y_train_minus_val,\n",
    "                    epochs=10,\n",
    "                    batch_size=216,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['order',\n",
       " 'partner',\n",
       " 'match',\n",
       " 'samerace',\n",
       " 'dec_o',\n",
       " 'field',\n",
       " 'from',\n",
       " 'zipcode',\n",
       " 'career',\n",
       " 'dec']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
