{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment 8: PageRank with Spark**\n",
    "\n",
    "Amanda Baker, adbaker\n",
    "\n",
    "Below is the outline of pyspark code for calculating the pagerank of a graph expressed in the edge vector representation.  For this past of the assignment:\n",
    "\n",
    "1. Complete the code below\n",
    "2. Write doc string comments for all functions documenting what they do\n",
    "3. Test your code on other graphs we've worked in previous assignments\n",
    "\n",
    "I recommend reviewing the (i) the Excel spread sheet calculation we did for simulating the page rank calculation (ii) and slides on pagerank.  Ensure you under the algorithm well before starting on this exercise. \n",
    "\n",
    "Rather than just stating \"Write PySpark code to calculate PageRank\" I've provided some helper functions and sample output along the way to provide guidance.  To faciliate grading, do stay with these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    '''helper method of read_graph; takes in a line from a file (line must be in format: [page name, page neighbor, \n",
    "    page neighbor, ... page neighbor]) and parses the line to return the page and a list of its neighbors'''\n",
    "    line = line.split()\n",
    "    y = line[0]\n",
    "    neighbors_lst = [line[i] for i in range(1,len(line))]\n",
    "    return y, neighbors_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph(fname):\n",
    "    '''reads a file, parses each line with function parse_line, and returns an RDD of all pages and a list of that page's\n",
    "    neighbors'''\n",
    "    file = sc.textFile(fname)\n",
    "    graph = file.map(lambda x: parse_line(x))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', ['B', 'C']), ('B', ['C']), ('C', ['A']), ('D', ['C'])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_graph('graph-1.txt').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In init_ranks you will need to use what is termed a \"broadcast\" variable. Do read online about these.  Following are some links \n",
    "[link 1](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-broadcast.html), [link 2](https://umbertogriffo.gitbooks.io/apache-spark-best-practices-and-tuning/content/when_to_use_broadcast_variable.html), [link 3](https://spark.apache.org/docs/2.2.0/rdd-programming-guide.html#shared-variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def init_ranks(graph):\n",
    "    '''initializes page ranks based on the number of pages to be ranked, and returns and RDD of pages and their \n",
    "    initial ranking'''\n",
    "    num_nodes = graph.count()\n",
    "    init_ranks = graph.map(lambda x: (x[0], 1/num_nodes))\n",
    "    return init_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 0.25), ('B', 0.25), ('C', 0.25), ('D', 0.25)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = read_graph('graph-1.txt')\n",
    "init_ranks(g).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_partials(x):\n",
    "    '''helper method of calc_contribs; calculates the probability of navigating to a neighbor page based on how many other pages\n",
    "    a user could navigate to from the current page, and returns the page and its partial probability'''\n",
    "    for n in x[1][0]:\n",
    "        yield n, (1/len(x[1][0]))*x[1][1]\n",
    "    yield x[0], 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_contribs(ranks, graph):\n",
    "    '''joins the pages in a graph and their current ranks, and returns an RDD that contains a page \n",
    "    and a partial probability'''\n",
    "    join_r_g = graph.join(ranks)\n",
    "    contribs = join_r_g.flatMap(lambda x: calc_partials(x))\n",
    "    return contribs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = read_graph('graph-1.txt')\n",
    "r = init_ranks(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that when calculating the contributions we have A, B, C, D also paired with 0?  Why?**\n",
    "\n",
    "We also pair with 0 to ensure that websites that aren't linked to (like 'D' in graph-1.txt) aren't lost in the pageRank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B', 0.125),\n",
       " ('C', 0.125),\n",
       " ('A', 0),\n",
       " ('C', 0.25),\n",
       " ('B', 0),\n",
       " ('A', 0.25),\n",
       " ('C', 0),\n",
       " ('C', 0.25),\n",
       " ('D', 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = calc_contribs(r, g)\n",
    "c1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ranks(contribs, num_nodes, beta=.85):\n",
    "    '''groups all partial probabilities together by page (the key), and returns an RDD that calculates each page's\n",
    "    new rank by summing all partial probabilities, multipyling the sum by beta, and adding the product to (1-beta)/num_nodes;\n",
    "    returns an RDD of each page and it's new page rank'''\n",
    "    calc = contribs.groupByKey()\n",
    "    probs = calc.map(lambda x: (x[0], ((1-beta)/num_nodes) + (beta * sum(x[1]))))\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B', 0.14375), ('A', 0.25), ('C', 0.56875), ('D', 0.037500000000000006)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_ranks(c1, num_nodes=g.count(), beta=0.85).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(fname, beta=0.85, n=10):\n",
    "    '''calculates pagerank by reading in a graph of pages and page neighbors, intializing page ranks based on number of \n",
    "    pages, and re-calculating each page's rank n times; returns a list of tuples that include the page name and page rank'''\n",
    "    g = read_graph(fname)\n",
    "    r = init_ranks(g)\n",
    "    for i in range(n):    \n",
    "        c1 = calc_contribs(r, g)\n",
    "        r = calc_ranks(c1, num_nodes=g.count(), beta=0.85)\n",
    "    return r.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 0.375054382302053),\n",
       " ('B', 0.1949370588413849),\n",
       " ('C', 0.3925085588565621),\n",
       " ('D', 0.037500000000000006)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pagerank('graph-1.txt', beta=0.85, n=10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# expected output for graph-1.txt\n",
    "[('A', 0.375054382302053),\n",
    " ('B', 0.1949370588413849),\n",
    " ('C', 0.3925085588565621),\n",
    " ('D', 0.037500000000000006)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***Additional testing on graph-2.txt and wikipedia-example.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 0.3552329235133619),\n",
       " ('B', 0.18087715033826585),\n",
       " ('C', 0.26671408227310545),\n",
       " ('D', 0.08133891194042742),\n",
       " ('E', 0.11583693193483957)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorted(pagerank('graph-2.txt', beta=0.85, n=10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# output from graph-2.txt pagerank\n",
    "[('A', 0.3552329235133619),\n",
    " ('B', 0.18087715033826585),\n",
    " ('C', 0.26671408227310545),\n",
    " ('D', 0.08133891194042742),\n",
    " ('E', 0.11583693193483957)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 0.02764650931040434),\n",
       " ('B', 0.3036191818465732),\n",
       " ('C', 0.3097295723325943),\n",
       " ('D', 0.03297885857776607),\n",
       " ('E', 0.06821469112858616),\n",
       " ('F', 0.03297885857776607),\n",
       " ('G', 0.01363636363636364),\n",
       " ('H', 0.01363636363636364),\n",
       " ('I', 0.01363636363636364),\n",
       " ('J', 0.01363636363636364),\n",
       " ('K', 0.01363636363636364)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorted(pagerank('wikipedia-example.txt', beta=.85, n=10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# output from wikipedia-example.txt pagerank\n",
    "[('A', 0.02764650931040434),\n",
    " ('B', 0.3036191818465732),\n",
    " ('C', 0.3097295723325943),\n",
    " ('D', 0.03297885857776607),\n",
    " ('E', 0.06821469112858616),\n",
    " ('F', 0.03297885857776607),\n",
    " ('G', 0.01363636363636364),\n",
    " ('H', 0.01363636363636364),\n",
    " ('I', 0.01363636363636364),\n",
    " ('J', 0.01363636363636364),\n",
    " ('K', 0.01363636363636364)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
