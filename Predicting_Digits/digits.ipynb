{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5: Feature Engineering\n",
    "### Team 9: Aysha Machingara and Amanda Baker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run read_all_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = read_all_image_label('train_images.txt', 'train_labels.txt')\n",
    "X_test, y_test = read_all_image_label('test_images.txt', 'test_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000\n",
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "# verify all samples have been read\n",
    "print(len(X_train), len(y_train))\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                            ',\n",
       " '                            ',\n",
       " '                            ',\n",
       " '                            ',\n",
       " '                            ',\n",
       " '           +++######+       ',\n",
       " '         ++##########+      ',\n",
       " '         +############+     ',\n",
       " '         +###+++++####+     ',\n",
       " '          +++     ###+      ',\n",
       " '                 +###+      ',\n",
       " '                ++###       ',\n",
       " '              +######       ',\n",
       " '         ++########++       ',\n",
       " '        +#########+         ',\n",
       " '        +##########+        ',\n",
       " '         ++++++++##+        ',\n",
       " '                 ##+        ',\n",
       " '                +##+        ',\n",
       " '       +       +###+        ',\n",
       " '     ++#+     +####+        ',\n",
       " '     ###+++++####++         ',\n",
       " '     ###########+           ',\n",
       " '     ++#######++            ',\n",
       " '       +##+++               ',\n",
       " '                            ',\n",
       " '                            ',\n",
       " '                            ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample observation\n",
    "X_train[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def img2array(img, lbl):\n",
    "    'Convert the image (as 28 x 28 grid) to a single numpy array'\n",
    "    s = ''.join(img)   \n",
    "    arr = [char2num(c) for c in s]\n",
    "    return np.array(arr)\n",
    "\n",
    "def char2num(c):\n",
    "    '''Convert a character to a number, in order to encode the digits (images).\n",
    "    This is done because scikit requires everything to be expressed as numbers'''\n",
    "    if c == ' ':\n",
    "        n = 0\n",
    "    elif c == '+':\n",
    "        n = 1\n",
    "    elif c == '#':\n",
    "        n = 1\n",
    "    else:\n",
    "        raise Exception('Invalid char %s' % c)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = np.array(y_train)\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "X_train_np = [img2array(img, lbl) for img, lbl in zip(X_train, y_train_np)]\n",
    "X_test_np = [img2array(img, lbl) for img, lbl in zip(X_test, y_train_np)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying length of array for given 'digit'\n",
    "len(X_train_np[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perform Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79        90\n",
      "           1       0.62      0.98      0.76       108\n",
      "           2       0.79      0.22      0.35       103\n",
      "           3       0.67      0.24      0.35       100\n",
      "           4       0.68      0.18      0.28       107\n",
      "           5       0.45      0.05      0.10        92\n",
      "           6       0.53      0.80      0.64        91\n",
      "           7       0.78      0.26      0.39       106\n",
      "           8       0.29      0.60      0.39       103\n",
      "           9       0.38      0.88      0.53       100\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      1000\n",
      "   macro avg       0.59      0.51      0.46      1000\n",
      "weighted avg       0.59      0.51      0.46      1000\n",
      "\n",
      "[[ 77   0   0   0   0   1   7   0   5   0]\n",
      " [  0 106   0   0   0   0   1   0   1   0]\n",
      " [  6   8  23   8   2   1  32   1  21   1]\n",
      " [  4  10   1  24   0   1  11   2  37  10]\n",
      " [  4   3   2   1  19   1   7   0  23  47]\n",
      " [ 11   6   1   0   1   5   4   0  54  10]\n",
      " [  1   8   1   0   1   1  73   0   6   0]\n",
      " [  0   6   0   2   2   1   1  28   3  63]\n",
      " [  2  20   1   1   2   0   2   2  62  11]\n",
      " [  1   4   0   0   1   0   0   3   3  88]]\n"
     ]
    }
   ],
   "source": [
    "# GaussianNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "gaus_model = GaussianNB()\n",
    "\n",
    "gaus_model.fit(X_train_np, y_train_np)\n",
    "predicted = gaus_model.predict(X_test_np)\n",
    "expected = y_test_np\n",
    "\n",
    "print(metrics.accuracy_score(expected, predicted))\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89        90\n",
      "           1       0.86      0.94      0.90       108\n",
      "           2       0.87      0.75      0.80       103\n",
      "           3       0.71      0.84      0.77       100\n",
      "           4       0.75      0.67      0.71       107\n",
      "           5       0.80      0.51      0.62        92\n",
      "           6       0.80      0.79      0.80        91\n",
      "           7       0.89      0.71      0.79       106\n",
      "           8       0.58      0.64      0.61       103\n",
      "           9       0.55      0.81      0.66       100\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1000\n",
      "   macro avg       0.77      0.75      0.75      1000\n",
      "weighted avg       0.77      0.75      0.75      1000\n",
      "\n",
      "[[ 78   0   1   0   0   1   3   0   7   0]\n",
      " [  0 102   0   0   0   0   1   0   5   0]\n",
      " [  1   2  77   3   2   1   6   1  10   0]\n",
      " [  0   0   0  84   0   1   2   4   2   7]\n",
      " [  0   0   2   0  72   1   4   0   3  25]\n",
      " [  2   1   1  17   4  47   2   1   9   8]\n",
      " [  2   5   2   0   3   3  72   0   4   0]\n",
      " [  0   5   3   0   4   0   0  75   4  15]\n",
      " [  1   2   3  12   3   5   0   1  66  10]\n",
      " [  1   1   0   3   8   0   0   2   4  81]]\n"
     ]
    }
   ],
   "source": [
    "#MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "multinom_model = MultinomialNB()\n",
    "\n",
    "multinom_model.fit(X_train_np, y_train_np)\n",
    "predicted = multinom_model.predict(X_test_np)\n",
    "expected = y_test_np\n",
    "\n",
    "print(metrics.accuracy_score(expected, predicted))\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88        90\n",
      "           1       0.83      0.96      0.89       108\n",
      "           2       0.85      0.78      0.81       103\n",
      "           3       0.71      0.79      0.75       100\n",
      "           4       0.78      0.77      0.77       107\n",
      "           5       0.73      0.67      0.70        92\n",
      "           6       0.81      0.76      0.78        91\n",
      "           7       0.87      0.73      0.79       106\n",
      "           8       0.75      0.60      0.67       103\n",
      "           9       0.58      0.80      0.67       100\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1000\n",
      "   macro avg       0.78      0.77      0.77      1000\n",
      "weighted avg       0.78      0.77      0.77      1000\n",
      "\n",
      "[[ 76   0   1   0   1   5   3   0   4   0]\n",
      " [  0 104   1   0   0   2   1   0   0   0]\n",
      " [  1   3  80   4   1   0   6   1   5   2]\n",
      " [  0   2   0  79   0   3   2   6   2   6]\n",
      " [  0   1   0   0  82   0   3   1   2  18]\n",
      " [  2   2   1  12   3  62   1   1   2   6]\n",
      " [  1   6   4   0   4   5  69   0   2   0]\n",
      " [  0   6   3   0   3   0   0  77   3  14]\n",
      " [  2   1   3  14   2   6   0   1  62  12]\n",
      " [  1   1   1   3   9   2   0   2   1  80]]\n"
     ]
    }
   ],
   "source": [
    "#BernoulliNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bern_model = BernoulliNB()\n",
    "\n",
    "bern_model.fit(X_train_np, y_train_np)\n",
    "predicted = bern_model.predict(X_test_np)\n",
    "expected = y_test_np\n",
    "\n",
    "print(metrics.accuracy_score(expected, predicted))\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Analyze and Report the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assess the performance of the trained classifiers (reports printed above).\n",
    "\n",
    "**Analysis:** The Bernoulli Naive Bayes model performs best, because features are treated as independent binary variables. In this case, we're looking at the presence of a 1 or 0 per feature, and so the absense of a 1 for a given feature is just as important as its presence. \n",
    "\n",
    "2. Which digits are poorly classified? \n",
    "\n",
    "**Answer:** 5s and 8s are particularly poorly classified (5s often get classified as 3s, and 8s often get classified as either 3s or 9s). It seems like very often the model predicts a 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: changing '+' char to be represented by a 0 instead of a 1 (adjusting for intensity of ink)\n",
    "\n",
    "def img2array_multi(img, lbl):\n",
    "    'Convert the image (as 28 x 28 grid) to a single numpy array'\n",
    "    s = ''.join(img)   \n",
    "    arr = [char2num_multi(c) for c in s]\n",
    "    return np.array(arr)\n",
    "\n",
    "def char2num_multi(c):\n",
    "    '''Convert a character to a number, in order to encode the digits (images).\n",
    "    This is done because scikit requires everything to be expressed as numbers'''\n",
    "    if c == ' ':\n",
    "        n = 0\n",
    "    elif c == '+':\n",
    "        n = 0\n",
    "    elif c == '#':\n",
    "        n = 1\n",
    "    else:\n",
    "        raise Exception('Invalid char %s' % c)\n",
    "    return n\n",
    "\n",
    "X_train_np_f1 = [img2array_multi(img, lbl) for img, lbl in zip(X_train, y_train_np)]\n",
    "X_test_np_f1 = [img2array_multi(img, lbl) for img, lbl in zip(X_test, y_train_np)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88        90\n",
      "           1       0.75      0.95      0.84       108\n",
      "           2       0.85      0.66      0.74       103\n",
      "           3       0.76      0.76      0.76       100\n",
      "           4       0.72      0.73      0.72       107\n",
      "           5       0.62      0.72      0.67        92\n",
      "           6       0.81      0.76      0.78        91\n",
      "           7       0.89      0.70      0.78       106\n",
      "           8       0.72      0.56      0.63       103\n",
      "           9       0.58      0.80      0.67       100\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1000\n",
      "   macro avg       0.76      0.75      0.75      1000\n",
      "weighted avg       0.76      0.75      0.75      1000\n",
      "\n",
      "[[ 75   0   1   1   0   7   4   0   2   0]\n",
      " [  0 103   0   0   0   2   1   0   2   0]\n",
      " [  2   9  68   6   1   1   6   2   7   1]\n",
      " [  0   3   1  76   0   9   1   3   2   5]\n",
      " [  0   0   0   0  78   1   2   1   2  23]\n",
      " [  1   2   1   7   4  66   1   1   3   6]\n",
      " [  0   5   3   0   6   7  69   0   1   0]\n",
      " [  0   7   3   0   5   0   0  74   2  15]\n",
      " [  1   6   3   8   5  11   1   1  58   9]\n",
      " [  1   2   0   2  10   2   0   1   2  80]]\n"
     ]
    }
   ],
   "source": [
    "bern_model_f1 = BernoulliNB()\n",
    "\n",
    "bern_model_f1.fit(X_train_np_f1, y_train_np)\n",
    "predicted_f1 = bern_model_f1.predict(X_test_np_f1)\n",
    "expected_f1 = y_test_np\n",
    "\n",
    "print(metrics.accuracy_score(expected_f1, predicted_f1))\n",
    "print(metrics.classification_report(expected_f1, predicted_f1))\n",
    "print(metrics.confusion_matrix(expected_f1, predicted_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: adding a \"density\" feature (summing counts of '+' and '#')\n",
    "\n",
    "def img2array_sum_arr(img, lbl):\n",
    "    'Convert the image (as 28 x 28 grid) to a single numpy array'\n",
    "    s = ''.join(img)   \n",
    "    arr = [char2num_multi(c) for c in s]\n",
    "    arr.append(np.sum(arr))\n",
    "    return np.array(arr)\n",
    "\n",
    "def char2num_sum_arr(c):\n",
    "    '''Convert a character to a number, in order to encode the digits (images).\n",
    "    This is done because scikit requires everything to be expressed as numbers'''\n",
    "    if c == ' ':\n",
    "        n = 0\n",
    "    elif c == '+':\n",
    "        n = 1\n",
    "    elif c == '#':\n",
    "        n = 1\n",
    "    else:\n",
    "        raise Exception('Invalid char %s' % c)\n",
    "    return n\n",
    "\n",
    "X_train_np_f2 = [img2array_sum_arr(img, lbl) for img, lbl in zip(X_train, y_train_np)]\n",
    "X_test_np_f2 = [img2array_sum_arr(img, lbl) for img, lbl in zip(X_test, y_train_np)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88        90\n",
      "           1       0.75      0.95      0.84       108\n",
      "           2       0.85      0.66      0.74       103\n",
      "           3       0.76      0.76      0.76       100\n",
      "           4       0.72      0.73      0.72       107\n",
      "           5       0.62      0.72      0.67        92\n",
      "           6       0.81      0.76      0.78        91\n",
      "           7       0.89      0.70      0.78       106\n",
      "           8       0.72      0.56      0.63       103\n",
      "           9       0.58      0.80      0.67       100\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1000\n",
      "   macro avg       0.76      0.75      0.75      1000\n",
      "weighted avg       0.76      0.75      0.75      1000\n",
      "\n",
      "[[ 75   0   1   1   0   7   4   0   2   0]\n",
      " [  0 103   0   0   0   2   1   0   2   0]\n",
      " [  2   9  68   6   1   1   6   2   7   1]\n",
      " [  0   3   1  76   0   9   1   3   2   5]\n",
      " [  0   0   0   0  78   1   2   1   2  23]\n",
      " [  1   2   1   7   4  66   1   1   3   6]\n",
      " [  0   5   3   0   6   7  69   0   1   0]\n",
      " [  0   7   3   0   5   0   0  74   2  15]\n",
      " [  1   6   3   8   5  11   1   1  58   9]\n",
      " [  1   2   0   2  10   2   0   1   2  80]]\n"
     ]
    }
   ],
   "source": [
    "bern_model_f2 = BernoulliNB()\n",
    "\n",
    "bern_model_f2.fit(X_train_np_f2, y_train_np)\n",
    "predicted_f2 = bern_model_f2.predict(X_test_np_f2)\n",
    "expected_f2 = y_test_np\n",
    "\n",
    "print(metrics.accuracy_score(expected_f2, predicted_f2))\n",
    "print(metrics.classification_report(expected_f2, predicted_f2))\n",
    "print(metrics.confusion_matrix(expected_f2, predicted_f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: mean and variance\n",
    "# significantly **reduces** accuracy for Multinomial and Bernoulli, and significantly **increases** accuracy on Gaussian model\n",
    "\n",
    "def img2array_sum_arr(img, lbl):\n",
    "    'Convert the image (as 28 x 28 grid) to a single numpy array'\n",
    "    s = ''.join(img)   \n",
    "    arr = [char2num_sum_arr(c) for c in s]\n",
    "    arr2 = []\n",
    "    arr2.append(np.sum(arr))\n",
    "    for i in range(784):\n",
    "        if i % 28 == 0:\n",
    "            arr2.append(np.mean(arr[i:i+28]))\n",
    "            arr2.append(np.var(arr[i:i+28]))\n",
    "    return np.array(arr2)\n",
    "\n",
    "def char2num_sum_arr(c):\n",
    "    '''Convert a character to a number, in order to encode the digits (images).\n",
    "    This is done because scikit requires everything to be expressed as numbers'''\n",
    "    if c == ' ':\n",
    "        n = 0\n",
    "    elif c == '+':\n",
    "        n = 1\n",
    "    elif c == '#':\n",
    "        n = 1\n",
    "    else:\n",
    "        raise Exception('Invalid char %s' % c)\n",
    "    return n\n",
    "\n",
    "X_train_np_f2 = [img2array_sum_arr(img, lbl) for img, lbl in zip(X_train, y_train_np)]\n",
    "X_test_np_f2 = [img2array_sum_arr(img, lbl) for img, lbl in zip(X_test, y_train_np)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.59      0.57        90\n",
      "           1       0.79      0.95      0.87       108\n",
      "           2       0.73      0.59      0.65       103\n",
      "           3       0.45      0.59      0.51       100\n",
      "           4       0.89      0.78      0.83       107\n",
      "           5       0.50      0.24      0.32        92\n",
      "           6       0.76      0.84      0.80        91\n",
      "           7       0.75      0.77      0.76       106\n",
      "           8       0.58      0.58      0.58       103\n",
      "           9       0.71      0.77      0.74       100\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1000\n",
      "   macro avg       0.67      0.67      0.66      1000\n",
      "weighted avg       0.68      0.68      0.67      1000\n",
      "\n",
      "[[ 53   0   3   3   0   3   2   0  26   0]\n",
      " [  0 103   0   0   2   0   2   1   0   0]\n",
      " [  7   2  61  15   0   3  14   0   1   0]\n",
      " [  7   4   4  59   0  11   0   7   6   2]\n",
      " [  2   4   1   0  83   0   4   1   3   9]\n",
      " [  4   1   4  43   0  22   0  10   4   4]\n",
      " [  1   1   8   0   1   3  76   0   1   0]\n",
      " [  0   4   3   0   0   2   0  82   1  14]\n",
      " [ 21   7   0   7   1   0   2   2  60   3]\n",
      " [  2   4   0   3   6   0   0   6   2  77]]\n"
     ]
    }
   ],
   "source": [
    "bern_model_f2 = GaussianNB()\n",
    "\n",
    "bern_model_f2.fit(X_train_np_f2, y_train_np)\n",
    "predicted_f2 = bern_model_f2.predict(X_test_np_f2)\n",
    "expected_f2 = y_test_np\n",
    "\n",
    "print(metrics.accuracy_score(expected_f2, predicted_f2))\n",
    "print(metrics.classification_report(expected_f2, predicted_f2))\n",
    "print(metrics.confusion_matrix(expected_f2, predicted_f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: number of '1's on either side of a '1'\n",
    "\n",
    "def img2array_distance(img, lbl):\n",
    "    'Convert the image (as 28 x 28 grid) to a single numpy array'\n",
    "    s = ''.join(img)   \n",
    "    arr = [char2num_distance(c) for c in s]\n",
    "    arr2 = []\n",
    "    for i in range(784):\n",
    "        if arr[i] == 1:\n",
    "            neighbors = arr[i-1] + arr[i+1]\n",
    "            arr2.append(neighbors)\n",
    "        else:\n",
    "            arr2.append(0)\n",
    "    return np.array(arr2)\n",
    "\n",
    "def char2num_distance(c):\n",
    "    '''Convert a character to a number, in order to encode the digits (images).\n",
    "    This is done because scikit requires everything to be expressed as numbers'''\n",
    "    if c == ' ':\n",
    "        n = 0\n",
    "    elif c == '+':\n",
    "        n = 1\n",
    "    elif c == '#':\n",
    "        n = 1\n",
    "    else:\n",
    "        raise Exception('Invalid char %s' % c)\n",
    "    return n\n",
    "\n",
    "X_train_np_f3 = [img2array_distance(img, lbl) for img, lbl in zip(X_train, y_train_np)]\n",
    "X_test_np_f3 = [img2array_distance(img, lbl) for img, lbl in zip(X_test, y_train_np)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88        90\n",
      "           1       0.83      0.96      0.89       108\n",
      "           2       0.86      0.77      0.81       103\n",
      "           3       0.71      0.79      0.75       100\n",
      "           4       0.77      0.76      0.76       107\n",
      "           5       0.71      0.67      0.69        92\n",
      "           6       0.81      0.75      0.78        91\n",
      "           7       0.87      0.73      0.79       106\n",
      "           8       0.75      0.60      0.67       103\n",
      "           9       0.58      0.80      0.67       100\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1000\n",
      "   macro avg       0.78      0.77      0.77      1000\n",
      "weighted avg       0.78      0.77      0.77      1000\n",
      "\n",
      "[[ 76   0   1   0   1   5   3   0   4   0]\n",
      " [  0 104   1   0   0   2   1   0   0   0]\n",
      " [  2   3  79   4   1   0   6   1   5   2]\n",
      " [  0   2   0  79   0   3   2   6   2   6]\n",
      " [  0   1   0   0  81   0   3   1   2  19]\n",
      " [  2   2   1  12   3  62   1   1   2   6]\n",
      " [  1   6   4   0   4   6  68   0   2   0]\n",
      " [  0   6   3   0   3   0   0  77   3  14]\n",
      " [  1   1   3  14   2   7   0   1  62  12]\n",
      " [  1   1   0   3  10   2   0   2   1  80]]\n"
     ]
    }
   ],
   "source": [
    "bern_model_f3 = BernoulliNB()\n",
    "\n",
    "bern_model_f3.fit(X_train_np_f3, y_train_np)\n",
    "predicted_f3 = bern_model_f3.predict(X_test_np_f3)\n",
    "expected_f3 = y_test_np\n",
    "\n",
    "print(metrics.accuracy_score(expected_f3, predicted_f3))\n",
    "print(metrics.classification_report(expected_f3, predicted_f3))\n",
    "print(metrics.confusion_matrix(expected_f3, predicted_f3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best one so far!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: reducing features by taking the max at every 2nd pixel and every 4th pixel\n",
    "\n",
    "def img2array_mean(img, lbl):\n",
    "    'Convert the image (as 28 x 28 grid) to a single numpy array'\n",
    "    s = ''.join(img)   \n",
    "    arr = [char2num_mean(c) for c in s]\n",
    "    arr2 = []\n",
    "    arr2.append(np.sum(arr))\n",
    "    for i in range(784):\n",
    "        if i % 2 == 0:\n",
    "            arr2.append(np.max(arr[i:i+1]))\n",
    "        if i % 7 == 0:\n",
    "            arr2.append(np.max(arr[i:i+6]))\n",
    "        if i % 8 == 0:\n",
    "            arr2.append(arr[i])\n",
    "    return np.array(arr2)\n",
    "\n",
    "def char2num_mean(c):\n",
    "    '''Convert a character to a number, in order to encode the digits (images).\n",
    "    This is done because scikit requires everything to be expressed as numbers'''\n",
    "    if c == ' ':\n",
    "        n = 0\n",
    "    elif c == '+':\n",
    "        n = 1\n",
    "    elif c == '#':\n",
    "        n = 2\n",
    "    else:\n",
    "        raise Exception('Invalid char %s' % c)\n",
    "    return n\n",
    "\n",
    "X_train_np_f4 = [img2array_mean(img, lbl) for img, lbl in zip(X_train, y_train_np)]\n",
    "X_test_np_f4 = [img2array_mean(img, lbl) for img, lbl in zip(X_test, y_train_np)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87        90\n",
      "           1       0.84      0.95      0.90       108\n",
      "           2       0.88      0.74      0.80       103\n",
      "           3       0.72      0.81      0.76       100\n",
      "           4       0.79      0.73      0.76       107\n",
      "           5       0.81      0.74      0.77        92\n",
      "           6       0.78      0.82      0.80        91\n",
      "           7       0.84      0.72      0.77       106\n",
      "           8       0.80      0.69      0.74       103\n",
      "           9       0.58      0.81      0.68       100\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1000\n",
      "   macro avg       0.80      0.78      0.79      1000\n",
      "weighted avg       0.80      0.78      0.79      1000\n",
      "\n",
      "[[ 75   0   0   0   0   4   5   0   6   0]\n",
      " [  0 103   1   0   0   1   1   0   1   1]\n",
      " [  1   3  76   8   2   0   7   1   5   0]\n",
      " [  0   2   0  81   0   2   1   6   1   7]\n",
      " [  0   1   1   0  78   0   3   1   2  21]\n",
      " [  3   0   1   7   2  68   1   2   1   7]\n",
      " [  1   5   1   0   2   6  75   0   1   0]\n",
      " [  0   7   4   0   2   0   0  76   1  16]\n",
      " [  2   1   2  11   2   2   3   3  71   6]\n",
      " [  0   0   0   5  11   1   0   2   0  81]]\n"
     ]
    }
   ],
   "source": [
    "bern_model_f4 = BernoulliNB()\n",
    "\n",
    "bern_model_f4.fit(X_train_np_f4, y_train_np)\n",
    "predicted_f4 = bern_model_f4.predict(X_test_np_f4)\n",
    "expected_f4 = y_test_np\n",
    "\n",
    "print(metrics.accuracy_score(expected_f4, predicted_f4))\n",
    "print(metrics.classification_report(expected_f4, predicted_f4))\n",
    "print(metrics.confusion_matrix(expected_f4, predicted_f4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: reducing features by taking the max at every 2nd pixel and every 4th pixel plus additional features\n",
    "\n",
    "def img2array_5(img, lbl):\n",
    "    'Convert the image (as 28 x 28 grid) to a single numpy array'\n",
    "    s = ''.join(img)   \n",
    "    arr = [char2num_5(c) for c in s]\n",
    "    arr2 = []\n",
    "    arr2.append(arr[260])\n",
    "    arr2.append(arr[520])\n",
    "    for i in range(784):\n",
    "        if i % 8 == 0:\n",
    "            arr2.append(arr[i])\n",
    "        if i % 23 == 0:\n",
    "            arr2.append(arr[i]) \n",
    "        if i % 26 == 0:\n",
    "            arr2.append(arr[i])       \n",
    "    return np.array(arr2)\n",
    "\n",
    "def char2num_5(c):\n",
    "    '''Convert a character to a number, in order to encode the digits (images).\n",
    "    This is done because scikit requires everything to be expressed as numbers'''\n",
    "    if c == ' ':\n",
    "        n = 0\n",
    "    elif c == '+':\n",
    "        n = 0\n",
    "    elif c == '#':\n",
    "        n = 1\n",
    "    else:\n",
    "        raise Exception('Invalid char %s' % c)\n",
    "    return n\n",
    "\n",
    "X_train_np_f5 = [img2array_5(img, lbl) for img, lbl in zip(X_train, y_train_np)]\n",
    "X_test_np_f5 = [img2array_5(img, lbl) for img, lbl in zip(X_test, y_train_np)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85        90\n",
      "           1       0.76      0.91      0.83       108\n",
      "           2       0.90      0.63      0.74       103\n",
      "           3       0.69      0.75      0.72       100\n",
      "           4       0.65      0.68      0.67       107\n",
      "           5       0.65      0.48      0.55        92\n",
      "           6       0.73      0.64      0.68        91\n",
      "           7       0.76      0.65      0.70       106\n",
      "           8       0.64      0.62      0.63       103\n",
      "           9       0.54      0.80      0.65       100\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      1000\n",
      "   macro avg       0.72      0.70      0.70      1000\n",
      "weighted avg       0.72      0.70      0.70      1000\n",
      "\n",
      "[[78  0  0  1  2  3  3  0  3  0]\n",
      " [ 0 98  0  0  0  3  1  0  1  5]\n",
      " [ 1  7 65  5  4  1  5  1 13  1]\n",
      " [ 1  4  1 75  0  3  1  6  2  7]\n",
      " [ 0  2  1  0 73  0  4  4  2 21]\n",
      " [ 6  0  0 14  6 44  2  4  7  9]\n",
      " [ 3 10  2  0 10  7 58  0  1  0]\n",
      " [ 0  5  2  0  4  1  1 69  6 18]\n",
      " [ 2  3  1 11  2  5  4  4 64  7]\n",
      " [ 2  0  0  2 11  1  0  3  1 80]]\n"
     ]
    }
   ],
   "source": [
    "bern_model_f5 = BernoulliNB()\n",
    "\n",
    "bern_model_f5.fit(X_train_np_f5, y_train_np)\n",
    "predicted_f5 = bern_model_f5.predict(X_test_np_f5)\n",
    "expected_f5 = y_test_np\n",
    "\n",
    "print(metrics.accuracy_score(expected_f5, predicted_f5))\n",
    "print(metrics.classification_report(expected_f5, predicted_f5))\n",
    "print(metrics.confusion_matrix(expected_f5, predicted_f5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: adding symetry as a feature\n",
    "\n",
    "# def img2array_6(img, lbl):\n",
    "#     'Convert the image (as 28 x 28 grid) to a single numpy array'\n",
    "#     s = ''.join(img)   \n",
    "#     arr = [char2num_6(c) for c in s]\n",
    "#     sym_arr_full = []\n",
    "#     sym_arr_left = []\n",
    "#     sym_arr_right = []\n",
    "#     for rec in arr:\n",
    "#         for i in range(784):\n",
    "#             if i == 0 or i % 28 == 0:\n",
    "#                 sym_arr_left.append(np.sum(arr[i:i+13]))\n",
    "#             if i % 14 == 0:\n",
    "#                 sym_arr_right.append(np.sum(arr[i:i+13]))\n",
    "#     sym_arr_full.append(sym_arr_left)\n",
    "#     return np.array(sym_arr_full)\n",
    "\n",
    "# def char2num_6(c):\n",
    "#     '''Convert a character to a number, in order to encode the digits (images).\n",
    "#     This is done because scikit requires everything to be expressed as numbers'''\n",
    "#     if c == ' ':\n",
    "#         n = 0\n",
    "#     elif c == '+':\n",
    "#         n = 1\n",
    "#     elif c == '#':\n",
    "#         n = 1\n",
    "#     else:\n",
    "#         raise Exception('Invalid char %s' % c)\n",
    "#     return n\n",
    "\n",
    "# X_train_np_f6 = [img2array_6(img, lbl) for img, lbl in zip(X_train, y_train_np)]\n",
    "# X_test_np_f6 = [img2array_6(img, lbl) for img, lbl in zip(X_test, y_train_np)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bern_model_f6 = BernoulliNB()\n",
    "\n",
    "# bern_model_f6.fit(X_train_np_f6, y_train_np)\n",
    "# predicted_f6 = bern_model_f6.predict(X_test_np_f6)\n",
    "# expected_f6 = y_test_np\n",
    "\n",
    "# print(metrics.accuracy_score(expected_f6, predicted_f6))\n",
    "# print(metrics.classification_report(expected_f6, predicted_f6))\n",
    "# print(metrics.confusion_matrix(expected_f6, predicted_f6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idea: ratio of white space to dark space\n",
    "\n",
    "def img2array_7(img, lbl):\n",
    "    'Convert the image (as 28 x 28 grid) to a single numpy array'\n",
    "    s = ''.join(img)   \n",
    "    arr = [char2num_5(c) for c in s]\n",
    "    arr2 = []\n",
    "    for i in range(784):\n",
    "        if arr[i] == 0:\n",
    "            sum_zeros += 1\n",
    "        else:\n",
    "            sum_ones += 1\n",
    "        arr2.append(sum_zeros)\n",
    "        arr2.append(sum_ones)\n",
    "    return np.array(arr2)\n",
    "\n",
    "X_train_np_f7 = [img2array_5(img, lbl) for img, lbl in zip(X_train, y_train_np)]\n",
    "X_test_np_f7 = [img2array_5(img, lbl) for img, lbl in zip(X_test, y_train_np)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85        90\n",
      "           1       0.76      0.91      0.83       108\n",
      "           2       0.90      0.63      0.74       103\n",
      "           3       0.69      0.75      0.72       100\n",
      "           4       0.65      0.68      0.67       107\n",
      "           5       0.65      0.48      0.55        92\n",
      "           6       0.73      0.64      0.68        91\n",
      "           7       0.76      0.65      0.70       106\n",
      "           8       0.64      0.62      0.63       103\n",
      "           9       0.54      0.80      0.65       100\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      1000\n",
      "   macro avg       0.72      0.70      0.70      1000\n",
      "weighted avg       0.72      0.70      0.70      1000\n",
      "\n",
      "[[78  0  0  1  2  3  3  0  3  0]\n",
      " [ 0 98  0  0  0  3  1  0  1  5]\n",
      " [ 1  7 65  5  4  1  5  1 13  1]\n",
      " [ 1  4  1 75  0  3  1  6  2  7]\n",
      " [ 0  2  1  0 73  0  4  4  2 21]\n",
      " [ 6  0  0 14  6 44  2  4  7  9]\n",
      " [ 3 10  2  0 10  7 58  0  1  0]\n",
      " [ 0  5  2  0  4  1  1 69  6 18]\n",
      " [ 2  3  1 11  2  5  4  4 64  7]\n",
      " [ 2  0  0  2 11  1  0  3  1 80]]\n"
     ]
    }
   ],
   "source": [
    "bern_model_f7 = BernoulliNB()\n",
    "\n",
    "bern_model_f7.fit(X_train_np_f7, y_train_np)\n",
    "predicted_f7 = bern_model_f7.predict(X_test_np_f7)\n",
    "expected_f7 = y_test_np\n",
    "\n",
    "print(metrics.accuracy_score(expected_f7, predicted_f7))\n",
    "print(metrics.classification_report(expected_f7, predicted_f7))\n",
    "print(metrics.confusion_matrix(expected_f7, predicted_f7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This one also improved Gaussian quite a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idea: using PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def img2array_distance_0s(img, lbl):\n",
    "    'Convert the image (as 28 x 28 grid) to a single numpy array'\n",
    "    s = ''.join(img)   \n",
    "    arr = [(1, char2num_5(c)) for c in s]\n",
    "    pca = PCA(svd_solver='full')\n",
    "    arr2 = pca.fit_transform(arr)\n",
    "    return np.array(arr2).reshape(-1)\n",
    "\n",
    "X_train_np_f8 = [img2array_distance_0s(img, lbl) for img, lbl in zip(X_train, y_train_np)]\n",
    "X_test_np_f8 = [img2array_distance_0s(img, lbl) for img, lbl in zip(X_test, y_train_np)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.66      0.72        90\n",
      "           1       0.81      0.97      0.89       108\n",
      "           2       0.73      0.54      0.62       103\n",
      "           3       0.72      0.53      0.61       100\n",
      "           4       0.57      0.54      0.56       107\n",
      "           5       0.42      0.46      0.44        92\n",
      "           6       0.70      0.74      0.72        91\n",
      "           7       0.70      0.73      0.71       106\n",
      "           8       0.56      0.50      0.53       103\n",
      "           9       0.50      0.73      0.59       100\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      1000\n",
      "   macro avg       0.65      0.64      0.64      1000\n",
      "weighted avg       0.65      0.64      0.64      1000\n",
      "\n",
      "[[ 59   0   2   1   2  13   4   0   9   0]\n",
      " [  0 105   0   0   1   0   1   0   1   0]\n",
      " [  2   3  56   5   3   5  15   1  12   1]\n",
      " [  1   4   2  53   3  18   2   5   2  10]\n",
      " [  2   3   5   1  58   2   4  10   0  22]\n",
      " [  5   2   2   5  14  42   1   2  10   9]\n",
      " [  1   5   7   0   3   7  67   0   1   0]\n",
      " [  0   5   0   3   6   2   0  77   2  11]\n",
      " [  3   1   2   6   6  10   2   1  51  21]\n",
      " [  2   1   1   0   6   0   0  14   3  73]]\n"
     ]
    }
   ],
   "source": [
    "bern_model_f8 = GaussianNB()\n",
    "\n",
    "bern_model_f8.fit(X_train_np_f8, y_train_np)\n",
    "predicted_f8 = bern_model_f8.predict(X_test_np_f8)\n",
    "expected_f8 = y_test_np\n",
    "\n",
    "print(metrics.accuracy_score(expected_f8, predicted_f8))\n",
    "print(metrics.classification_report(expected_f8, predicted_f8))\n",
    "print(metrics.confusion_matrix(expected_f8, predicted_f8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Thoughts:** \n",
    "\n",
    "Based on our research, convnets have the best accuracy in terms of classifying the handwritten digits. However, with Naive Bayes Classifiers the accuracy results are generally much lower, as we've seen through multiple attempts at improving each of the three types (Multinomial, Bernoulli, and Gaussian). Ultimately we were able to increase accuracy the most in a Gaussian NB classifier, but could only achieve slight increases in Multinomial and Binomial NB models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
